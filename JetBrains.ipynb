{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "JetBrains.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2-gGKB3kVR0",
        "colab_type": "code",
        "outputId": "80808bb1-dec6-478b-c91c-1ccbbf50a979",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install catboost\n",
        "! pip install transformers\n",
        "! pip install lightgbm\n",
        "! pip install pytorch_pretrained_bert\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# data prep\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# model\n",
        "import transformers as ppb \n",
        "import lightgbm as lgb\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import KFold\n",
        "import catboost\n",
        "import torch\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertConfig\n",
        "from pytorch_pretrained_bert import  BertConfig, BertModel, BertForMaskedLM \n",
        "from pytorch_pretrained_bert.optimization import BertAdam, WarmupLinearSchedule\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: catboost in /usr/local/lib/python3.6/dist-packages (0.22)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from catboost) (3.2.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from catboost) (1.4.1)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.0.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.6/dist-packages (from catboost) (4.4.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.18.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from catboost) (1.12.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (2.4.6)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (1.1.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly->catboost) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->catboost) (46.0.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.7.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.85)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.2)\n",
            "Requirement already satisfied: tokenizers==0.5.2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.38)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.33)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.1)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.33 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.33)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.33->boto3->transformers) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.33->boto3->transformers) (0.15.2)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.6/dist-packages (2.2.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from lightgbm) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from lightgbm) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from lightgbm) (1.18.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->lightgbm) (0.14.1)\n",
            "Requirement already satisfied: pytorch_pretrained_bert in /usr/local/lib/python3.6/dist-packages (0.6.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (4.38.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.18.2)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.12.33)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.4.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2.21.0)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.33 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (1.15.33)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.9.5)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.33->boto3->pytorch_pretrained_bert) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.33->boto3->pytorch_pretrained_bert) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.16.0,>=1.15.33->boto3->pytorch_pretrained_bert) (1.12.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9d2cd5tmGq9",
        "colab_type": "code",
        "outputId": "99955c74-0b51-46b2-dbb8-6e5cb253ee35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOsi01iMmMaI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SEED = 43\n",
        "np.random.seed(SEED)\n",
        "\n",
        "columns = [\"text\", \"parent_text\", \"score\"]\n",
        "df = pd.concat([\n",
        "    pd.read_csv(\"/content/drive/My Drive/Kaggle/Twits/Data/comments_positive.csv\", usecols=columns, na_filter=False),\n",
        "    pd.read_csv(\"/content/drive/My Drive/Kaggle/Twits/Data/comments_negative.csv\", usecols=columns, na_filter=False)\n",
        "], ignore_index=True)\n",
        "\n",
        "#df = df.rename(columns = {'score':'label'})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-PWHOhPA_eQ",
        "colab_type": "text"
      },
      "source": [
        "## Missing and duplicated values\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGPUTKI0A-Y0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.isna().sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpGVye2q03Vc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "drop_rows = list(df[(df['text'].isin([' ']) == True)].index) + list(df[(df['parent_text'].isin([' ']) == True)].index) + \\\n",
        " list(df[(df['text'].isin(['']) == True)].index) + list(df[(df['parent_text'].isin(['']) == True)].index)\n",
        "\n",
        "a = df.groupby(by = ['text','parent_text']).count()\n",
        "duplicates = list(a[a['score']>1].index)\n",
        "len(duplicates)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtS7Nvdn5may",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "same_scoe = []\n",
        "different_score = []\n",
        "for i in range(len(duplicates)):\n",
        "  check = df[(df['text'] == duplicates[i][0]) & (df['parent_text'] == duplicates[i][1])]\n",
        "  if all(check['score'] == check['score'].mean()): # some duplicatec could have the same scores so its i am not going to drop\n",
        "    same_scoe.extend(list(check.index))\n",
        "  else:\n",
        "    different_score.extend(list(check.index))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNTcRGJHL5gO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "to_drop = list(set(different_score + drop_rows))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFz3tt2dM_cs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(to_drop)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJ-l-bH3umkd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('/content/drive/My Drive/Kaggle/Twits/Data/drop_rows.txt', 'w') as f:\n",
        "    for item in to_drop:\n",
        "        f.write(str(item) + '\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9MrKEaEIinH",
        "colab_type": "text"
      },
      "source": [
        "## Upload the indexes to drop and crate the cleaned dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ps9Sj2wUGyWt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "drop_indexes = []\n",
        "with open('/content/drive/My Drive/Kaggle/Twits/Data/drop_rows.txt', 'r') as f:\n",
        "    for _ in range(10390):\n",
        "        drop_indexes.append(float(f.readline().strip(\"\\n\")))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLSLRPNfIPFy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.drop(drop_indexes)\n",
        "df.reset_index(drop = True,inplace = True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwI3v6nKna9i",
        "colab_type": "text"
      },
      "source": [
        "## The dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Voc6l6EfeYur",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = df['score']\n",
        "df.drop(columns='score', inplace=True)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.05, random_state=SEED)\n",
        "\n",
        "#To be sure we don't use indices to predict something\n",
        "X_train.reset_index(drop=True, inplace=True)\n",
        "X_test.reset_index(drop=True, inplace=True)\n",
        "y_train.reset_index(drop=True, inplace=True)\n",
        "y_test.reset_index(drop=True, inplace=True)\n",
        "\n",
        "print(\"Train shape: {}\".format(X_train.shape))\n",
        "print(\"Test shape: {}\".format(X_test.shape))\n",
        "\n",
        "X_train['score'] = y_train\n",
        "X_test['score'] = y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7zJe59WXEKP",
        "colab_type": "text"
      },
      "source": [
        "## Prepare the Data with the BERT Model Time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VeYqlNwoX2bJ",
        "colab_type": "text"
      },
      "source": [
        "### Data processor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKUpMFP-X58j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataProcessor():\n",
        "    def __init__(self,train,test,max_seq_length):\n",
        "        self.train_df = train\n",
        "        self.test_df = test\n",
        "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "        self.max_seq_length = max_seq_length\n",
        "        \n",
        "    def _tokenization(self,name):\n",
        "        if name == 'train':\n",
        "            df_data = self.train_df\n",
        "            \n",
        "        elif name == 'test':\n",
        "            df_data = self.test_df\n",
        "        texts = df_data.text\n",
        "        all_tokens = []\n",
        "       \n",
        "        for text in texts:\n",
        "            text = self.tokenizer.tokenize(text)\n",
        "            text = text[:self.max_seq_length - 2]\n",
        "            input_sequence = ['[CLS]'] + text + ['[SEP]']\n",
        "            pad_len = self.max_seq_length - len(input_sequence)\n",
        "            \n",
        "            tokens = self.tokenizer.convert_tokens_to_ids(input_sequence)\n",
        "            tokens += [0] * pad_len\n",
        "            \n",
        "            all_tokens.append(tokens)\n",
        "           \n",
        "        return np.array(all_tokens)\n",
        "    def get_train_test_features(self):\n",
        "        train_features = self._tokenization('train')\n",
        "        test_features = self._tokenization('test')\n",
        "        return train_features,test_features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLCS_V1Qps8F",
        "colab_type": "text"
      },
      "source": [
        "Because i don't have quite powerfull machine to train the NN i decided to bootstrap the part of the dataset for train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjRoEqaSu_GM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_bootstrap_samples(data, n_samples):\n",
        "    np.random.seed(42)\n",
        "    indices = np.random.randint(0, len(data), n_samples)\n",
        "    samples = data.loc[indices]\n",
        "    return samples\n",
        "\n",
        "n_samples = 1000000\n",
        "X_train_bs = get_bootstrap_samples(X_train, n_samples).reset_index(drop = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNp4dpp7w1xY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Positive scores: \",np.sum(X_train_bs['score']>0))\n",
        "print(\"Negative scores: \",np.sum(X_train_bs['score']<0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmXUCQa1GBrF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
        "model = model_class.from_pretrained(pretrained_weights) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOMoChaF3-ln",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_emb(X_train_bs,X_test,feature,max_seq_length,model):\n",
        "  \n",
        "  X_train = X_train_bs[[feature,'score']].copy()\n",
        "  X_test = X_test[[feature,'score']].copy() # for now i dont need the test\n",
        "  \n",
        "  if feature == 'parent_text':\n",
        "    X_train = X_train.rename(columns = {'parent_text':'text'})\n",
        "    X_test = X_test.rename(columns = {'parent_text':'text'})\n",
        "\n",
        "\n",
        "  data_process = DataProcessor(X_train,X_test,max_seq_length)\n",
        "  train_features,test_features = data_process.get_train_test_features()\n",
        "\n",
        "  input_ids = torch.tensor([f for f in train_features])\n",
        "\n",
        "  with torch.no_grad():\n",
        "    last_hidden_states = model(input_ids)\n",
        "    \n",
        "  out = pd.DataFrame(last_hidden_states[0][:,0,:].numpy())\n",
        "  out['Score'] = np.array(X_train['score'])\n",
        "  return out\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dR9y7xXbEs_s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "step = 1000\n",
        "max_seq_length = 64\n",
        "slices = np.arange(0,len(X_train_bs)+step,step)\n",
        "features = pd.DataFrame()\n",
        "feature = 'parent_text'\n",
        "for i in range (600,len(slices)-1,1):\n",
        "  print(slices[i],slices[i+1])\n",
        "  if i == 0 :\n",
        "    data = X_train_bs.loc[slices[i]:slices[i+1]].reset_index(drop = True)\n",
        "  else: \n",
        "    data = X_train_bs.loc[slices[i]+1:slices[i+1]].reset_index(drop = True)\n",
        "  \n",
        "  out = get_emb(data,X_test.loc[:1],feature,max_seq_length,model)\n",
        "  features = features.append(out).reset_index(drop = True)\n",
        "  if slices[i+1] % 50000 == 0:\n",
        "    features.to_csv(\"/content/drive/My Drive/Kaggle/Twits/Data/parent_text_\" + str(slices[i+1]) + \".csv\")\n",
        "    features = pd.DataFrame()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyYdP1fNSrE9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "step = 1000\n",
        "max_seq_length = 64\n",
        "slices = np.arange(0,len(X_train_bs)+step,step)\n",
        "features = pd.DataFrame()\n",
        "feature = 'text'\n",
        "for i in range (50,len(slices)-1):\n",
        "  print(slices[i],slices[i+1])\n",
        "  if i == 0 :\n",
        "    data = X_train_bs.loc[slices[i]:slices[i+1]].reset_index(drop = True)\n",
        "  else: \n",
        "    data = X_train_bs.loc[slices[i]+1:slices[i+1]].reset_index(drop = True)\n",
        "  \n",
        "  out = get_emb(data,X_test.loc[:1],feature,max_seq_length,model)\n",
        "  features = features.append(out).reset_index(drop = True)\n",
        "  if slices[i+1] % 50000 == 0:\n",
        "    features.to_csv(\"/content/drive/My Drive/Kaggle/Twits/Data/text_\" + str(slices[i+1]) + \".csv\")\n",
        "    features = pd.DataFrame()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbgf3GAOSsSi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fr = 50000\n",
        "to = 300000\n",
        "step = 50000\n",
        "parent_text = [\"parent_text_\" + str(i) + \".csv\" for i in range(fr,to+1,step)]\n",
        "text = [\"text_\" + str(i) + \".csv\"  for i in range(fr,to+1,step)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3qRzkjwSGZ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "parent_data = pd.DataFrame()\n",
        "for i in range(len(parent_text)):\n",
        "  if i == 0:\n",
        "    parent_data = pd.read_csv(\"/content/drive/My Drive/Kaggle/Twits/Data/\" + parent_text[i])\n",
        "  else:\n",
        "    parent_data = parent_data.append(pd.read_csv(\"/content/drive/My Drive/Kaggle/Twits/Data/\" + parent_text[i])).reset_index(drop = True)\n",
        "parent_data.reset_index(drop = True,inplace = True)\n",
        "parent_data.drop(columns = 'Unnamed: 0',inplace = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWUdB_-KKhyV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(text)):\n",
        "  if i == 0:\n",
        "    text_data = pd.read_csv(\"/content/drive/My Drive/Kaggle/Twits/Data/\" + text[i])\n",
        "  else:\n",
        "    text_data = text_data.append(pd.read_csv(\"/content/drive/My Drive/Kaggle/Twits/Data/\" + text[i]), error_bad_lines=False).reset_index(drop = True)\n",
        " \n",
        "text_data.reset_index(drop = True,inplace = True)\n",
        "text_data.drop(columns = 'Unnamed: 0',inplace = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIpV6RHGuoOs",
        "colab_type": "code",
        "outputId": "1d24f82c-96f0-47fb-9c18-3171105354b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(sum(parent_data['Score'] == text_data['Score']))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "300001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTgMeOGxOoRg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "parent_data = parent_data.add_suffix('_parent')\n",
        "text_data = text_data.add_suffix('_text')\n",
        "data = pd.concat([parent_data, text_data], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAjhcYmRCSCG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del parent_data,text_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6WBYsQJ1D_m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.to_csv('/content/drive/My Drive/Kaggle/Twits/Data/prep_data2.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8yMo7W0FA7H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZNdjfeu9wZu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "step = 1000\n",
        "max_seq_length = 64\n",
        "slices = np.arange(0,len(X_test)+step,step)\n",
        "features = pd.DataFrame()\n",
        "feature = 'parent_text'\n",
        "for i in range (0,len(slices)-1,1):\n",
        "  print(slices[i],slices[i+1])\n",
        "  if i == 0 :\n",
        "    data = X_test.loc[slices[i]:slices[i+1]].reset_index(drop = True)\n",
        "  else: \n",
        "    data = X_test.loc[slices[i]+1:slices[i+1]].reset_index(drop = True)\n",
        "  \n",
        "  out = get_emb(data,data.loc[:1],feature,max_seq_length,model)\n",
        "  features = features.append(out).reset_index(drop = True)\n",
        "  if slices[i+1] % 50000 == 0 or slices[i+1]>199000:\n",
        "    features.to_csv(\"/content/drive/My Drive/Kaggle/Twits/Data/test_parent_text_\" + str(slices[i+1]) + \".csv\")\n",
        "    features = pd.DataFrame()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1hcQh3mD4S6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "step = 1000\n",
        "max_seq_length = 64\n",
        "slices = np.arange(0,len(X_test)+step,step)\n",
        "features = pd.DataFrame()\n",
        "feature = 'text'\n",
        "for i in range (0,len(slices)-1,1):\n",
        "  print(slices[i],slices[i+1])\n",
        "  if i == 0 :\n",
        "    data = X_test.loc[slices[i]:slices[i+1]].reset_index(drop = True)\n",
        "  else: \n",
        "    data = X_test.loc[slices[i]+1:slices[i+1]].reset_index(drop = True)\n",
        "  \n",
        "  out = get_emb(data,data.loc[:1],feature,max_seq_length,model)\n",
        "  features = features.append(out).reset_index(drop = True)\n",
        "  if slices[i+1] % 50000 == 0 or slices[i+1]>199000 :\n",
        "    features.to_csv(\"/content/drive/My Drive/Kaggle/Twits/Data/test_text_\" + str(slices[i+1]) + \".csv\")\n",
        "    features = pd.DataFrame()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMX69o5XD5RE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fr = 50000\n",
        "to = 200000\n",
        "step = 50000\n",
        "parent_text = [\"test_parent_text_\" + str(i) + \".csv\" for i in range(fr,to+1,step)]\n",
        "text = [\"test_text_\" + str(i) + \".csv\"  for i in range(fr,to+1,step)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzNEZ-8iUlhi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "parent_data = pd.DataFrame()\n",
        "for i in range(len(parent_text)):\n",
        "  if i == 0:\n",
        "    parent_data = pd.read_csv(\"/content/drive/My Drive/Kaggle/Twits/Data/\" + parent_text[i])\n",
        "  else:\n",
        "    parent_data = parent_data.append(pd.read_csv(\"/content/drive/My Drive/Kaggle/Twits/Data/\" + parent_text[i])).reset_index(drop = True)\n",
        "parent_data.reset_index(drop = True,inplace = True)\n",
        "parent_data.drop(columns = 'Unnamed: 0',inplace = True)\n",
        "\n",
        "text_data = pd.DataFrame()\n",
        "for i in range(len(text)):\n",
        "  if i == 0:\n",
        "    text_data = pd.read_csv(\"/content/drive/My Drive/Kaggle/Twits/Data/\" + text[i])\n",
        "  else:\n",
        "    text_data = text_data.append(pd.read_csv(\"/content/drive/My Drive/Kaggle/Twits/Data/\" + text[i])).reset_index(drop = True)\n",
        " \n",
        "text_data.reset_index(drop = True,inplace = True)\n",
        "text_data.drop(columns = 'Unnamed: 0',inplace = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgSlsK3QLVKI",
        "colab_type": "code",
        "outputId": "6e53fbec-9ec0-4344-ab6f-ba389b0865c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(sum(parent_data['Score'] == text_data['Score']))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "199481\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYLc-lHlLXlP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "parent_data = parent_data.add_suffix('_parent')\n",
        "text_data = text_data.add_suffix('_text')\n",
        "data = pd.concat([parent_data, text_data], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zj6TqRukLba8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del parent_data,text_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzrXnnKBLeJn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.to_csv('/content/drive/My Drive/Kaggle/Twits/Data/prep_test_data2.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVjl0OyxLiEf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYsrCSPeD6Ru",
        "colab_type": "text"
      },
      "source": [
        "##Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3V_aCh4VF3ps",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = pd.read_csv('/content/drive/My Drive/Kaggle/Twits/Data/prep_data.csv',engine = None).iloc[:300000]\n",
        "df_test = pd.read_csv('/content/drive/My Drive/Kaggle/Twits/Data/prep_test_data.csv',engine = None)\n",
        "\n",
        "df_train.drop(columns = \"Unnamed: 0\",inplace = True)\n",
        "df_train.drop(columns = 'Score_text',inplace = True)\n",
        "\n",
        "df_test.drop(columns = \"Unnamed: 0\",inplace = True)\n",
        "df_test.drop(columns = 'Score_text',inplace = True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sz7lDo7qCxKw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = df_train.rename(columns = {'Score_parent':\"Score\"})\n",
        "df_test = df_test.rename(columns = {'Score_parent':\"Score\"})\n",
        "\n",
        "y = df_train['Score']\n",
        "df_train.drop(columns = 'Score',inplace = True)\n",
        "\n",
        "y_test = df_test[\"Score\"]\n",
        "df_test.drop(columns = 'Score',inplace = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aXjlEPzQDVu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def model_lgb(df_train, y,df_test, random_state = 123, n_splits = 5):\n",
        "    \n",
        "    \n",
        "    params = {\n",
        "            'boosting_type': 'gbdt',\n",
        "            'objective': 'regression',\n",
        "            'metric': {'l2'},\n",
        "            'num_leaves': 31,\n",
        "            'learning_rate': 0.1,\n",
        "            'feature_fraction': 0.9,\n",
        "            'bagging_fraction': 0.8,\n",
        "            'bagging_freq': 5,\n",
        "            'n_estimators': 100,\n",
        "            'verbose':-1}      \n",
        "    #  Init predictions array with all zeroes\n",
        "    predictions = np.zeros(len(df_test))\n",
        "    \n",
        "    \n",
        "    mse_score = 0\n",
        "\n",
        "    print('Starting cross validation')\n",
        "\n",
        "    kf = KFold(n_splits=n_splits, shuffle = True, random_state = random_state)\n",
        "\n",
        "    for train_index, test_index in kf.split(df_train):\n",
        "\n",
        "        lgb_train = lgb.Dataset(df_train.iloc[train_index], y[train_index])\n",
        "        lgb_eval = lgb.Dataset(df_train.iloc[test_index], y[test_index], reference=lgb_train)\n",
        "        \n",
        "        gbm = lgb.train(params,\n",
        "                lgb_train,\n",
        "                valid_sets=lgb_eval,\n",
        "                num_boost_round = 1000,\n",
        "                early_stopping_rounds = 20,\n",
        "                verbose_eval=400,\n",
        "\n",
        "                )\n",
        "        print('Starting predicting...')\n",
        "        predictions += gbm.predict(df_test, num_iteration=gbm.best_iteration)\n",
        "       \n",
        "    \n",
        "        \n",
        "        \n",
        "        del lgb_train, lgb_eval,gbm\n",
        "    \n",
        "    #  Avarage probabilities and auc score\n",
        "    predictions = predictions / n_splits\n",
        "    \n",
        "\n",
        "    df_test['Predict_score'] = predictions\n",
        "  \n",
        "    return df_test['Predict_score'], mse_score\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7OBHLPdUp83",
        "colab_type": "code",
        "outputId": "1e9d288a-ff7e-42e2-a855-4351ebbf11ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "predcitions,avr_score = model_lgb(df_train,y, df_test, random_state = 123, n_splits = 5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting cross validation\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 20 rounds.\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 42799.3\n",
            "Starting predicting...\n",
            "Training until validation scores don't improve for 20 rounds.\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 42462.8\n",
            "Starting predicting...\n",
            "Training until validation scores don't improve for 20 rounds.\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 41652.5\n",
            "Starting predicting...\n",
            "Training until validation scores don't improve for 20 rounds.\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 41235.7\n",
            "Starting predicting...\n",
            "Training until validation scores don't improve for 20 rounds.\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[99]\tvalid_0's l2: 40587.6\n",
            "Starting predicting...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpibrruqcsyN",
        "colab_type": "code",
        "outputId": "bbd02384-2119-4530-cb4a-a697b39d601c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "mean_squared_error(y_test, predcitions)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "41193.56030789585"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QN-A2ArlUdLm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from catboost import CatBoostRegressor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJWeHpGJZa0B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "params = {'iterations': 1000,\n",
        "          'learning_rate':0.1,\n",
        "          'depth':8,\n",
        "          'loss_function':'RMSE',\n",
        "          'metric_period' : 50,\n",
        "          'l2_leaf_reg': 0.1,\n",
        "          'subsample':0.8,\n",
        "          'early_stopping_rounds':10\n",
        "          }\n",
        "model = CatBoostRegressor(**params)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dL1hl3X4U6jZ",
        "colab_type": "code",
        "outputId": "4568f93a-345e-4279-c280-ed0e5df3c3dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "model.fit(df_train,y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0:\tlearn: 211.0478068\ttotal: 2.24s\tremaining: 37m 14s\n",
            "50:\tlearn: 202.3939138\ttotal: 1m 37s\tremaining: 30m 13s\n",
            "100:\tlearn: 198.7838276\ttotal: 2m 59s\tremaining: 26m 37s\n",
            "150:\tlearn: 195.3626430\ttotal: 4m 12s\tremaining: 23m 42s\n",
            "200:\tlearn: 192.1775267\ttotal: 5m 25s\tremaining: 21m 32s\n",
            "250:\tlearn: 189.4240827\ttotal: 6m 36s\tremaining: 19m 44s\n",
            "300:\tlearn: 186.9011422\ttotal: 7m 49s\tremaining: 18m 9s\n",
            "350:\tlearn: 184.4694557\ttotal: 9m 2s\tremaining: 16m 42s\n",
            "400:\tlearn: 182.2155340\ttotal: 10m 12s\tremaining: 15m 14s\n",
            "450:\tlearn: 180.0673357\ttotal: 11m 23s\tremaining: 13m 52s\n",
            "500:\tlearn: 178.0081618\ttotal: 12m 34s\tremaining: 12m 31s\n",
            "550:\tlearn: 176.0371018\ttotal: 13m 46s\tremaining: 11m 13s\n",
            "600:\tlearn: 174.1727311\ttotal: 14m 58s\tremaining: 9m 56s\n",
            "650:\tlearn: 172.3998829\ttotal: 16m 9s\tremaining: 8m 39s\n",
            "700:\tlearn: 170.6819273\ttotal: 17m 22s\tremaining: 7m 24s\n",
            "750:\tlearn: 168.9812965\ttotal: 18m 35s\tremaining: 6m 9s\n",
            "800:\tlearn: 167.3448479\ttotal: 19m 47s\tremaining: 4m 54s\n",
            "850:\tlearn: 165.7451838\ttotal: 20m 58s\tremaining: 3m 40s\n",
            "900:\tlearn: 164.2350277\ttotal: 22m 9s\tremaining: 2m 26s\n",
            "950:\tlearn: 162.7616358\ttotal: 23m 22s\tremaining: 1m 12s\n",
            "999:\tlearn: 161.2413774\ttotal: 24m 33s\tremaining: 0us\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<catboost.core.CatBoostRegressor at 0x7f22460cea58>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLi_Dt3PWcsn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save_model('/content/drive/My Drive/Kaggle/Twits/catboost_model.cbm')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uQEoriwVXSk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = model.predict(df_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V00IGzN3cCOq",
        "colab_type": "code",
        "outputId": "60416471-e353-4d74-85e9-0514f23ad5ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "mean_squared_error(y_test, predictions)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "41775.52772067411"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kd29q1epvFZH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}